---
title: "10-23 Class Notes Using Regular Expressions"
author: "Sarah Cannon"
date: "10/23/2024"
output: html_document
---


# Announcements

Homework 7: If using extension hours, final deadline Thursday 10/24, 11:59pm 
Based on class on 10/16 (factors), half the length of a normal assignment

Homework 8, based on class this week, available tomorrow, due next Tuesday 10/29 

Upcoming office hours:

- Monday 1:15-2:15pm
- Tuesday 10:30-11:30 and 2-3pm
- Wednesday 1:15-2:15pm

QCL one-on-one appointments and drop-in schedule: https://www.cmc.edu/qcl/mentoring

Questions about upcoming schedule?


## Final Project

Description on Canvas (Files)

For now: Begin thinking of topics, finding data sets, brainstorming questions to ask about your data

Later: What makes a good question; Rubric; Project Proposal with detailed plan due November 19th (alongside Homework 10) 


# Using Regular Expressions

Preclass video:

- str_detect
- str_count
- str_replace, str_replace_all

Questions from preclass video? 

```{r, message = FALSE}
library(tidyverse)
```


## Counts, Proportions, Sums, and Means

Motivating Questions: 

- How many strings contain the pattern? 
- What proportion of strings contain the pattern?
- How many times does the pattern appear in total (non-overlapping)?
- How many times does the pattern appear in each string on average (non-overlapping)? 

Recall: Adding up true/false values tells you how many TRUEs there are. 

So: Use sum and sr_detect to count thenumber of strings in a list or a column that have a match

```{r}
greek <- c("alpha", "beta", "gamma", "iota")
str_detect(greek, "^g")
sum(str_detect(greek, "^g"))
```

Recall: Taking the mean of true/false values tells you what fraction of values are TRUE

So: use mean and str_detet to get the fraction of strings in which there is a match

```{r}
mean(str_detect(greek, "^g"))
```
A 0.25 fraction, or 25%, of the strings in the greek list begin with g

What if we don't care about whether or not a pattern appears, but how many times it appears? str_count

Find the average number of times a pattern appears in a string: 

```{r}
f <- c("apple", "banana", "cherry")
#Total
sum(str_count(f, "a"))
# Average
mean(str_count(f, "a"))
```

Works for larger lists too: To find the average number of times a appears in any fruit in the fruits list: 

```{r}
mean(str_count(fruit, "a"))
```

What if we use sum instead of mean? The total number of matches!

```{r}
sum(str_count(f, "a"))
```

Summary: 

*sum(str_detect(list, pattern))*: How many strings the pattern appears in

*sum(str_count(list, pattern))*: How many times the pattern appears in total across all the strings

*mean(str_detect(list, pattern))*: proportion of words a pattern appears in

*mean(str_count(list, pattern))*: average number of times a pattern appears per string


For all of these, can use for tibbles in a summarize(): 

```{r}
starwars
starwars %>% group_by(species) %>% 
  summarize(
  number_of_characters_with_digits_in_name = sum(str_detect(name, "\\d")),
  fraction_of_characters_with_digit_in_name = mean(str_detect(name, "\\d")), 
  averge_digits_per_name = mean(str_count(name, "\\d")), 
  total_digits_across_all_names = sum(str_count(name, "\\d"))
)
```



## Finding which strings in a list fit a pattern

Which sentences mention cats? 

Can see with str_view:

```{r}
str_view(sentences, "\\b[Cc]ats?\\b")
```

But what if want these sentences in a list/tibble so you can do more with them? 

There are several ways to do this, and the best method can depend on your data/what you're trying to do with it.

1. Use str_detect to get TRUE/FALSE list, keep only the TRUE entries

```{r}
contains_cat <- str_detect(sentences, "\\b[Cc]ats?\\b")
contains_cat %>% head(50)
sentences[contains_cat]
```

contains_cat: list of TRUE/FALSE values that say whether a cat is mentioned in the sentence or not

sentences[contains_cat]: only keeps those sentences where contains_cat is TRUE

We haven't used this notation before, but it's a lot like  filtering but for a list, not a tibble


2. str_subset: takes in list, returns a new list of the entries where pattern found. 

```{r}
str_subset(sentences,"\\b[Cc]ats?\\b")
```

Will not work in tibbles/with mutate. (because produces a list that's a different length than the list you started with)

*Note*: keeping FALSE values instead of TRUE values easier with Method 1


Question: What words in list words have no vowels in them? 

Answer Method 1. Find words with vowels, negate str_detect

```{r}
no_vowels <- !str_detect(words, "[aieou]")
words[no_vowels]
```


Answer Method 2. use str_subset: finding a regular expression for words with no vowels is harder! 

A single character that is not a vowel: [^aeiou]

Repeated any number of times: [^aeiou]+

Goes from start of string to end of string:^[^aeiou]+$

```{r}
str_subset(words, "^[^aeiou]+$")
```

Caution: Regular expressions can get complicated, think if there's an easier way to accomplish your goal (for example, finding words with vowels and negating with !)


3. Turn it into a tibble and filter (often best if want to do more operations!)

How to make a tibble: 

tibble(col1name = list_to_put_in_col1, col2name = list_to_put_in_col2, ...)

Put sentences in a tibble: 

```{r}
sentences_tibble <- tibble(sent = sentences)
sentences_tibble
sentences_tibble %>% filter(str_detect(sent, "\\b[Cc]ats?\\b"))
```

For many operations you may want to do, tibbles are much more convenient than lists! 

Most str_ functions: can use inside mutate, take <chr> column of tibble as first argument

To count number of words in each sentence: number of spaces plus one 

```{r}
sentences_tibble %>%
  mutate(num_words = str_count(sent, " ") + 1)
```

Works for any str_ entrywise functions whose output is the same length as the input column (e.g. str_detect, str_count, str_c), not functions where output is a different length than input (e.g. str_subset)


## Using code to make regular expressions

Let's find all sentences that contain one of several common animals 
(To start: ignore capitalization, allow to be subset of other words)

```{r}
animals <- c("cat", "dog", "mouse", "fox", "chicken", "bird")
```

(for many categories, can find lists to use for this rather than typing out your own - for example, R has built-in lists of colors and fruits) 

Make a regular expression, using or, that looks for any of these animals. 

Want: "cat|dog|mouse|fox|chicken|bird"

Use: str_c with collapse = "|"

```{r}
animals_regex <- str_c(animals, collapse = "|")
animals_regex
```

[can also use str_flatten - works similarly]

May be many cases where you want to use code and str_c to build regular expressions rather than typing them out by hand.

To only find these animal when they're not a subset of another word: 

```{r}
animals_regex <- str_c("\\b(", animals_regex, ")\\b")
animals_regex
```
[caution: only run this code chunk once!]

Now, look for sentences containing these (can do in list or tibble, I'll use tibbles here): 

```{r}
sentences_tibble %>% filter(str_detect(sent, animals_regex))
```




## str_extract, str_extract_all, unnesting

What if want to pull out which animal was found? 

Use str_extract: pulls out the *first* match for the pattern in the sentence, get NA if no match

```{r}
sentences_tibble %>% 
  mutate(animal_found = str_extract(sent, animals_regex)) 
```

But, when there were multiple animals in a string, only found first one: 

```{r}
sentences_tibble %>% 
  mutate(animal_found = str_extract(sent, animals_regex))  %>% 
  filter(!is.na(animal_found))
```

str_extract_all: 

```{r}
sentences_tibble %>% 
  filter(str_detect(sent, animals_regex)) %>% 
  mutate(animals_found = str_extract_all(sent, animals_regex))
```

Notation <chr [n]>: means this entry in the tibble is a list of length n of data type chr

Can use unnest_wider or unnest_longer to spread these values across multiple columns or rows (which to use depends on what you want to do - is an observation a sentence, or an appearance of an animal? Keep your data tidy!)

```{r}
sentences_tibble %>% 
  filter(str_detect(sent, animals_regex)) %>% 
  mutate(animals_found = str_extract_all(sent, animals_regex)) %>% 
  unnest_longer(animals_found)

```

Unnesting longer is useful if, for instance, you want to count how many times each animal appears

```{r}
sentences_tibble %>% 
  filter(str_detect(sent, animals_regex)) %>% 
  mutate(animals_found = str_extract_all(sent, animals_regex)) %>% 
  unnest_longer(animals_found) %>% 
  count(animals_found)
```

For unnest_wider will need to rename columns: use names_sep = "_", for example

(names_sep = what goes between column name and integer 1, 2, etc. )

```{r}
sentences_tibble %>% 
  filter(str_detect(sent, animals_regex)) %>% 
  mutate(animals_found = str_extract_all(sent, animals_regex)) %>% 
  unnest_wider(col = animals_found, names_sep = "_")
```

Will make however many columns are needed 

(number of columns = max number of animals per sentence)

Useful if you care about which animal was first, which was second, etc. 


## Grouping and capturing

Parentheses also have a *second* important effect in regular expressions: they create *capturing groups* that allow you to use the subcomponents of the match

The first way to use a capturing group is to refer back to it within a match with a *back reference*: \1 refers to the match contained within the first parenthesis, \2 the match in contained within the second parenthesis, etc. 

Find all fruits that have a repeated pair of letters: 

```{r}
 str_view(fruit, "(..)\\1")
```

(..): any two characters

\\1: whatever pattern matches what was inside the first set of parentheses

All words that start and end with the same letter: 

```{r}
str_view(words, "^(.).*\\1$")
```

Remember: Anytime you want a pattern to match the *whole* string, need to start pattern with ^ and end it with $

You can also use this in str_replace

To switch the order of the second and third words in sentences: 

Recall: \w matches any word character, i.e., letters and numbers

```{r}
sentences %>% head(5) %>% 
  str_replace("^(\\w+) (\\w+) (\\w+)", "\\1 \\3 \\2")
```

To extract only the part of the string that is in parentheses, rather than the whole match: 

Suppose we want to find all words linked by "and"

```{r}
sentences %>% head(20) %>% str_view("\\b\\w+\\b and \\b\\w+\\b")
```

To pull out only what's in one pair of parentheses: use str_extract() and specify a group. 

```{r}
sentences_tibble %>% head(20) %>% 
  mutate(word1 = str_extract(sent,"\\b(\\w+)\\b and \\b(\\w+)\\b", group = 1)) %>%
  mutate(word2 = str_extract(sent,"\\b(\\w+)\\b and \\b(\\w+)\\b", group = 2))
```

Or, to extract all groups at once, use extract(): 

```{r}
sentences_tibble %>% head(20) %>% 
  extract(sent, c("Word1", "Word2"), "\\b(\\w+)\\b and \\b(\\w+)\\b")
```



## str_split

Split string into multiple parts based on a separator which you specify

Similar to separate(), but more specialized, specifically for strings

```{r}
sentences %>% head(3) %>% str_split(" ")
```

Get a list of vectors of different lengths.

Can make a matrix instead, using simplify:

```{r}
sentences %>% head(3) %>% str_split(" ", simplify = TRUE)
```

(fills in with empty strings when necessary)
(these formats aren't particularly easy to work with)

To use for a tibble: 

```{r}
sentences_tibble %>% 
  head(10) %>% 
  mutate(split_sentences = str_split(sent, " ")) %>% unnest_longer(split_sentences)
```


Another approach: use the boundary() function

```{r}
z <- "This is a sentence.  This is another sentence. "
str_split(z, " ")
str_split(z, boundary("word"))
# Nicer because won't include punctuation with the words, for example
```

Can also split things up in other ways: 

```{r}
?boundary
```

Can split for "character", "line_break", "sentence", "word"


## Other useful regex functions we don't have enough time to cover

Maybe useful for final project

str_locate, str_locate_all: gets locations of matches within strings

separate_wider_regex: can separate strings based on patterns given by regular expressions


# Summary

- str_detect: Returns TRUE if match found, FALSE otherwise
- str_count: Returns number of matches found
- str_replace, str_replace_all: replace a pattern with some other string
- str_subset: Returns which strings in list have a match in them
- tibble: Makes a tibble, as in:
    tibble(col1name = list_to_put_in_col1, col2name = list_to_put_in_col2)
- str_c(list, collapse = "|"): Put all strings in list into a single string, separated by |
- str_extract, str_extract_all: extract the substring with the pattern
- unnest_wider, unnest_longer: When tibble entries are lists, spread them across multiple rows/columns
- str_split: splits string into multiple parts based on separator
- grouping and capturing: Can reference what matches the regular expression in the first pair of parentheses as \1, what's in the second set of parentheses as \2, etc. 


# Activity

On Canvas

If finish regular questions, move on to bonus questions.

If finish bonus questions, check in with Prof. Cannon, then can leave. 

Can work individually or with classmates. 
